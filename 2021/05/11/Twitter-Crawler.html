<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How I built a Twitter crawler | ahmedsamirio</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="How I built a Twitter crawler" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="blog" />
<meta property="og:description" content="blog" />
<link rel="canonical" href="https://ahmedsamirio.github.io/blog/2021/05/11/Twitter-Crawler.html" />
<meta property="og:url" content="https://ahmedsamirio.github.io/blog/2021/05/11/Twitter-Crawler.html" />
<meta property="og:site_name" content="ahmedsamirio" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-11T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How I built a Twitter crawler" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-05-11T00:00:00-05:00","datePublished":"2021-05-11T00:00:00-05:00","description":"blog","headline":"How I built a Twitter crawler","mainEntityOfPage":{"@type":"WebPage","@id":"https://ahmedsamirio.github.io/blog/2021/05/11/Twitter-Crawler.html"},"url":"https://ahmedsamirio.github.io/blog/2021/05/11/Twitter-Crawler.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ahmedsamirio.github.io/blog/feed.xml" title="ahmedsamirio" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">ahmedsamirio</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How I built a Twitter crawler</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-11T00:00:00-05:00" itemprop="datePublished">
        May 11, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><img src="https://www.price2spy.com/blog/wp-content/uploads/2019/06/crawl.jpg" alt="Header Image" /></p>

<p>I was curious to use twitter data for a project I had in mind, and basically it was a answering a bunch of question regarding the behavior of users on twitter and how that is correlated with their followers’ count. But when I got access to the developer’s API, I was lost on how to get the data that I want.</p>

<p>Of course there are a bunch of packages like Tweepy, Python-twitter, ptt (Python twitter tools) and even Twint (which doesn’t require access through Twitter’s API) which you can use to get data from twitter, but what kind of data did I want?</p>

<p>What I had in mind was to capture the recent behavior of a random group of users through mining their tweets, but the Twitter API requires searching by specific queries or hashtags, etc..</p>

<p>What I wanted was a random sample of users that isn’t affected by users tweeting about a certain topic, and that’s when a thought occurred to me. Why don’t I select a bunch of seed users, collect their latest tweets and then select a random subset of their friends and followers and do the same?</p>

<p>So this is just randomly traversing over a tree of users branched from a seed user until a certain depth, not unlike a binary search tree.</p>

<p><img src="../images/tree.png" alt="an image alt text" title="Binary Search Tree" /></p>

<p>We can see an example of a traversed tree from a seed user, let’s suppose <em>d</em> stands for a the level of a given layer, where the first layer’s level equals 0, the maximum depth of layers <em>l</em> is 3, the new users recursed over from a seed user is <em>n</em> is 2, and the tweets to collect is <em>t</em> is 1. If user A is the seed user, then we collect the latest tweet and select 2 random users from his friends and followers, which turned out to be B and C.</p>

<p>Then for each of these users we do the same as user A. This results for a total of <em>n^d</em> users for each layer where the starting layer <em>d</em> is 0, therefore the total number of users and tweets collected equals 2^3 + 2^2 + 2^1 + 1 = 15 users and 15 tweets.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">stream_from_users</span><span class="p">(</span><span class="n">seed_user</span><span class="p">,</span> <span class="n">tweets_per_user</span><span class="p">,</span> <span class="n">users_per_user</span><span class="p">,</span> <span class="n">depth</span><span class="p">):</span>
    <span class="n">tweets</span> <span class="o">=</span> <span class="n">collect_tweets</span><span class="p">(</span><span class="n">seed_user</span><span class="p">)</span>
    <span class="n">users</span> <span class="o">=</span> <span class="n">collect_random_users</span><span class="p">(</span><span class="n">seed_user</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">depth</span> <span class="o">&lt;</span> <span class="n">limit_depth</span><span class="p">:</span>
	<span class="k">for</span> <span class="n">user</span> <span class="ow">in</span> <span class="n">random_users</span><span class="p">:</span>
	    <span class="n">stream_from_users</span><span class="p">(</span><span class="n">seed_user</span><span class="p">,</span> <span class="n">tweets_per_user</span><span class="p">,</span> <span class="n">users_per_user</span><span class="p">,</span>
			      <span class="n">depth</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>This code snippet would serve to be the backbone of mining this data. But then I was faced with another question, which package should I use to get the data? and how shall I store it?</p>

<p>What I had in mind was starting with 3 seed users, and then recursing over them for 2 levels down, with 100 users per user and collecting 200 tweets per user (which is the limit of one request per user). So that would result in an estimated 30K users and 6 million tweets, how could I efficiently store this data?</p>

<p>I thought SQLite was the answer, but it turned out that I couldn’t do bulk inserts of up to 200 tweets into a table, where I had to loop over every collected tweet and store it which was pretty inefficient. I ended up using MongoDB, which was extremely useful in that matter, as it enabled bulk inserts of tweets in JSON format directly.</p>

<p>And then came the next hurdle, using Tweepy or Python-twitter was really easy, but when used for mining tweets they returned Status objects, where each object had a JSON attribute, but the Status object itself wasn’t supported for bulk inserts in MongoDB, so I would have had to loop over each object and save it’s JSON into the database, just like SQLite. And that’s why I used ptt, as it directly returned the tweets in JSON format, enabling bulk inserts.</p>

<p>Now it was just a matter of running the script, and then preparing the data in a format which enables answering the questions the I had in mind, which will be reserved for another post.</p>

<p>To make a dataset of your own, you can use the script provided in the following repo.
Github repo: <a href="https://github.com/ahmedsamirio/twitter-crawler">https://github.com/ahmedsamirio/twitter-crawler</a></p>

  </div><a class="u-url" href="/blog/2021/05/11/Twitter-Crawler.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/ahmedsamirio" target="_blank" title="ahmedsamirio"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/ahmedsamirio" target="_blank" title="ahmedsamirio"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
